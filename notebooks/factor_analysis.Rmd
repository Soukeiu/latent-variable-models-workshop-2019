---
title: "Factor Analysis"
output: 
  html_notebook: 
    code_folding: none
    highlight: pygments
    theme: sandstone
    toc: yes
editor_options: 
  chunk_output_type: inline
---

## Initialization

This assumes the prior Rmd files have been run.  See the README file.

```{r misc_functions}
source('functions_scripts/functions.R')
```

```{r load_packages, message=FALSE}
library(tidyverse)
library(psych)
```


## Single Factor

First, the data.  For our example we will use only the **agreeableness** items from the Big Five.

```{r agree}
bfi_agree = bfi %>% 
  select(matches('A[1-5]'))
```

```{r fa_graphical_model}
DiagrammeR::grViz('functions_scripts/fa_gm.gv')
```


### Inspect correlations

```{r cor_agree}
# note how A1 is negatively scored
cor_agree = cor(bfi_agree, use = 'pair')

cor_agree

cor_agree %>% 
  corPlot()
```

### Factor model

Let's run a factor analysis.  These items should belong to a single factor, so that's the model we'll run (default for `fa` is one factor).  

There are two parts to the output.  We will concern ourselves with the loadings first (`MR1`).  Conceptually they tell us how the observed variables are correlated with the latent variable.  The `h2` is the square of that, called the **communality**, and is like the R^2^ for that variable, i.e. how much of its observed variance is accounted for by the latent.  The `u2` is the **uniqueness**, or how much is not explained (1 - `h2`).  The final value is a measure of **complexity**. A value of 1 might be seen for something that loaded on only one factor, which is all we have here, but otherwise will increase the more the variable loads on multiple factors.

```{r fa_agree}
fa_agree = fa(bfi_agree)
fa_agree
```

A simple diagram explains the model and its result.

```{r fa_agree_vis}
fa.diagram(fa_agree)

# in case you are interested in how to make the graphviz file
# fa.graph(fa_agree,
#          rank.direction = 'TB', 
#          simple = F,
#          digits = 2,
#          out.file = 'functions_scripts/fa_agree.gv')

DiagrammeR::grViz('functions_scripts/fa_agree.gv')
```


## The Latent Linear Model

We can think of a factor analysis for a single variable in terms of just a basic regression model. For each observed variable as a dependent variable we have $\beta_0$ is the intercept and $\lambda$ the regression coefficient that expresses the effect of the latent variable $F$ on the observed variable $X$.

$$X = \beta_0 + \lambda F + \epsilon$$

We will almost always have multiple indicators, and often multiple latent variables.  Some indicators may be associated with multiple factors.

$$\begin{aligned}
X_1 &= \beta_{01} + \lambda_{11} F_1 + \lambda_{21} F_2  + \epsilon\\
X_2 &= \beta_{02} + \lambda_{12} F_1 + \lambda_{22} F_2  + \epsilon\\
X_3 &= \beta_{03} + \lambda_{13} F_1 + \epsilon
\end{aligned}$$

If we put this in matrix form as we did with PCA, we can see the key difference.  Factor analysis can only approximate the data, because the data is assumed to be measured with error.

$$X \approx F\Lambda'$$
Now in terms of the correlation matrix.  The $\Psi$ are the uniquenesses, or variance we don't account for.

$$R \approx \Lambda\Lambda' \\
R = \Lambda\Lambda' + \Psi$$


In terms of the multivariate normal distribution:

$$ X \sim \mathcal{N}(F\Lambda' + \mu, \Psi) $$
$\mu$ are the intercepts, $\Psi$ is a $DxD$ covariance matrix, with unique variances for each individual variable belonging to $X$ (and potentially residual covariances among the $X$).


#### Probabilistic PCA

Probabilistic PCA is a viable but not as commonly used variant.  One can see it as a restrictive form of factor analysis, where the variances of the items are constant.

$$\Psi = \sigma^2I$$

#### Standard PCA

Standard PCA is an even more extreme

With standard PCA we are assuming a noiseless process, and constraining $\Lambda$ to be orthogonal.

$$\sigma^2 \rightarrow 0$$

## Multiple Factors

Often we want to explore more than one factor. We'll use the `ability` data from the `psych` package to demonstrate this.

> 1525 subjects. Items are taken from the Synthetic Aperture Personality Assessment (SAPA) web based personality assessment project. 16 multiple choice ability items were sampled from 80 items given as part of the SAPA (https://sapa-project.org) project (Revelle, Wilt and Rosenthal, 2009; Condon and Revelle, 2014) to develop online measures of ability. 

They are broken down as follows:

- Basic reasoning
- Letter sequence
- Matrix reasoning
- Spatial rotation tasks

We will ignore the fact that these are binary for our purposes, but it really doesn't matter all that much in the grand scheme of things anyway.

```{r ability}
ability = as_tibble(ability)
ability
```

To allow for more than one factor, we specify the `nfactors` argument as desired.  Since we expect four factors, that's what we'll set the argument to.

```{r fa_ability}
fa_ability = fa(ability, nfactors = 4)
fa_ability
```

Interpretation is in general the same as with the single factor. Loadings give a sense of how an item correlates with a given factor (accounting for its correlation with other factors).  Let's look at it visually.  

```{r fa_ability_vis}
fa.diagram(fa_ability, sort = F)
```



Perhaps a couple items are not so great, and if we were more stringent, we might not be okay with this.  However, the other fit measures suggest the model is viable.


## Exercise

Go back to the `bfi` data and examine different factor solutions. The following visualization shows our factor analysis solution versus what we would have gotten against randomly resampled or simulated data.  The idea is to retain the number of factors for a model with a statistically higher eigenvalue than the random data.

Which one might you select?


```{r exercise1}
bfi_no_demo = bfi %>% select(-gender, -education, -age)
fa.parallel(bfi_no_demo, fa = 'fa', error.bars = T)
```


If you are familiar with some of the measures of fit and model comparison, feel free to use this custom function to easily assess both internal fit and comparison of different analyses.

```{r exercise2}
nf = 1:8
names(nf) = as.character(nf)

model_comparison(nflist)
```